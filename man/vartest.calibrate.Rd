% Generated by roxygen2 (4.0.2): do not edit by hand
\name{vartest.calibrate}
\alias{vartest.calibrate}
\title{Calibrating \code{vartest} for ABC}
\usage{
vartest.calibrate(n.of.x = NA, s.of.x = NA, n.of.y = NA, what = "MXPW",
  scale = n.of.x, mx.pw = 0.9, alpha = 0.01, tau.l = NA, tau.u = NA,
  tau.u.ub = NA, c.l = NA, c.u = NA, max.it = 100, tol = 1e-05,
  pow_scale = 1.5, debug = FALSE, plot = FALSE, verbose = FALSE)
}
\arguments{
\item{n.of.x}{Number of observed summary values}

\item{s.of.x}{Standard deviation of observed summary values}

\item{n.of.y}{Number of simulated summary values}

\item{what}{Character string to indicate the type of calibration to be performed}

\item{scale}{Scale parameter of the test statistic, usually \code{n.of.x}}

\item{mx.pw}{Maximum power at the point of equality}

\item{alpha}{Level of the equivalence test}

\item{tau.l}{Lower boundary point of the equivalence region}

\item{tau.u}{Upper boundary point of the equivalence region}

\item{tau.u.ub}{Guess on the upper boundary point of the equivalence region}

\item{c.l}{Lower boundary point of the critical region}

\item{c.u}{Upper boundary point of the critical region}

\item{max.it}{Maximum number of optimization steps at each calibration hierarchy}

\item{tol}{Required error tolerance in calibrating the actual maximum power to the requested maximum power}

\item{pow_scale}{Scale for the support of the standardized power. The power is truncated to \code{pow_scale*[-tau.u,tau.u]} and then standardized}

\item{debug}{Flag to switch off C implementation}

\item{plot}{Flag to plot calibrations}

\item{verbose}{Flag to run in verbose mode}

\item{plot_debug}{Flag to plot at each calibration iteration}
}
\value{
vector
}
\description{
Calibrate the one-sample equivalence test for population variances of normal summary values for ABC inference.
The one-sample \code{vartest} can be used to test the null hypothesis that the underlying population variance of the simulated summary values
is not similar to the variance of the observed summary values. It is applicable when the simulated and observed summary values follow a normal
distribution, or when normality cannot be rejected.

Different types of calibrations are available, see Notes for details:
\enumerate{
 \item (\code{what=ALPHA}) compute the ABC false positive rate for given critical region,
 \item (\code{what=CR}) calibrate the critical region for given ABC false positive rate,
 \item (\code{what=MXPW}) calibrate the critical region and the equivalence region for given ABC false positive rate and maximum power,
 \item (\code{what=KL}) calibrate the critical region, the equivalence region and the number of simulated summary values for given ABC false positive rate, maximum power and sample standard deviation of the observed data.
}

#' In the ideal case, the calibration KL is used. However, the KL calibration requires multiple i. i. d. instances of observed summary statistics
at each ABC iteration. If this is not available, the MXPW calibration should be used.

Depending on the type of calibration, some of the following inputs must be specified (see Examples).
}
\note{
\enumerate{
 \item (\code{what=ALPHA}) This calibration requires the inputs \code{c.l}, \code{c.u}, \code{tau.l}, \code{tau.u} with \code{c.l>tau.l}, \code{c.u<tau.u}, \code{tau.u>1}, \code{tau.l<1}.
				The output contains the corresponding ABC false positive rate \code{alpha}.
				This option does not specify any of the free ABC parameters, but may be useful to determine the ABC
				false positive rate for uncalibrated ABC routines.
 \item (\code{what=CR}) This calibration requires the inputs \code{tau.l}, \code{tau.u}, \code{alpha} with \code{tau.l<1}, \code{tau.u>1} and default \code{alpha=0.01}.
				The output contains the corresponding critical region \code{[c.l, c.u]}, which corresponds to the ABC tolerance region typically denoted by \code{[-epsilon, epsilon]}.
				This is an intermediate calibration step and may result in unsuitable power properties (see Examples).
 \item (\code{what=MXPW}) This calibration requires the inputs \code{alpha}, \code{mx.pw}, with default values 0.01 and 0.9 respectively.
				The output contains the corresponding critical region \code{[c.l, c.u]} (to be used in ABC, see Notes on (2)), and
				the corresponding equivalence region \code{[tau.l, tau.u]} that gives a suitable ABC accept/reject probability if the simulated summary values are close to the observed summary values.
				As a check to the numerical calibrations, the actual power at the point of equality is returned (\code{pw.cmx}).
\item (\code{what=KL}) This calibration can be used when a set of observed summary values is available. It is desirable because it specifies the number of simulated summary
				values so that the power is very close to the desired summary likelihood in terms of the KL divergence.
				The inputs are \code{alpha}, \code{mx.pw}, with default values 0.01 and 0.9 respectively.
				The output consists of the corresponding critical region \code{[c.l, c.u]} (to be used in ABC, see Notes on (2)), the equivalence
				region \code{[tau.l, tau.u]}, and the number of simulated summary values needed (\code{n.of.y}). As a check to the numerical calibrations,
				the KL divergence is returned (\code{KL}). It is desirable to compare the power to the summary likelihood in terms of the KL divergence, see References.
}
Note that the underlying test statistic only depends on \code{n.of.x}, \code{n.of.y}, \code{s.of.x}, which are all
known before ABC is run. Consequently, the free ABC parameters are calibrated once, before ABC is started.

The lower boundary point of the critical region \code{c.l} is calibrated numerically, so that
the power is maximized at the point of equality \code{rho=1}. The calibrated \code{c.l} does not equal 1/\code{c.u}.
}
\examples{
n.of.x	<- 60
n.of.y	<- 60

# Example 1: calibrate critical region and power of ABC accept/reject step (default)
# this requires to specify alpha, mx.pw (calibration parameters), 
# n.of.x, n.of.y (summary parameters), 
# tau.u.ub (for numerical optimization)
# note: this is the default calibration because it specifies all ABC parameters
# for sensible calibration parameters, and only requires minimal information on 
# the observed summary values. If a set of observed summary values is available,
# use the calibrations in Example 5.

vartest.calibrate(n.of.x=n.of.x, n.of.y=n.of.y, tau.u.ub=3, what='MXPW', mx.pw=0.9, alpha=0.01, plot=TRUE, verbose=FALSE)

# Example 2: calculate ABC false positive rate for given ABC tolerance
# this requires to specify c.l, c.u, tau.l, tau.u (ad-hoc ABC parameters), n.of.x, n.of.y (summary parameters)
# note: can be useful to compute the ABC false positive rate for uncalibrated ABC routines

vartest.calibrate(n.of.x=n.of.x, n.of.y=n.of.y, c.l=2/3, c.u=3/2, tau.l=1/2, tau.u=2, what='ALPHA', alpha=0.01, plot=TRUE, verbose=FALSE)

# Example 3: calibrate critical region for given ABC false positive rate and equivalence region
# this requires to specify alpha (calibration parameters), tau.l, tau.u (ad-hoc ABC parameter), n.of.x, n.of.y (summary parameters)
# note: this is just an intermediate calibration and may result in unsuitable power properties

vartest.calibrate(n.of.x=n.of.x, n.of.y=n.of.y, tau.l=1/2, tau.u=2, what='CR', alpha=0.01, plot=TRUE, verbose=FALSE)

# Example 4: calibrate critical region and location of maximum power of ABC accept/reject step
# this requires to specify alpha (calibration parameters), tau.u (ad-hoc ABC parameter), n.of.x, n.of.y (summary parameters)
# note: this is just an intermediate calibration and may result in unsuitable power properties

vartest.calibrate(n.of.x=n.of.x, n.of.y=n.of.y, tau.u=2, what='MXPW_AT_EQU', alpha=0.01, plot=TRUE, verbose=FALSE)

# Example 5: calibrate critical region, power of ABC accept/reject step, and #simulated data points
# this requires to specify alpha, mx.pw (calibration parameters), and n.of.x, s.of.x (summary parameters)
# note: the advantage here is that the KL divergence is also minimised, but we also
# need to have a set of observed summary values

xmean 		<- 1.2
xsigma 		<- 1.42
obs 		<- rnorm(n.of.x, xmean, xsigma)
obs 		<- (obs - mean(obs))/sd(obs) * xsigma + xmean
s.of.x		<- sd(obs)
n.of.y		<- NA	#this is now a calibration output
vartest.calibrate(n.of.x=n.of.x, s.of.x=s.of.x, what='KL', mx.pw=0.9, alpha=0.01, plot=TRUE, verbose=FALSE)
}
\references{
http://arxiv.org/abs/1305.4283
}
\seealso{
\code{\link{mutost.calibrate}}, \code{\link{ztest.calibrate}}
}

